{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: What are the Probability Mass Function(PMF) and Probability Density Function(PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Probability Mass Function(PMF) and Probability Density Function(PDF) are both ways of representing the probability distribution of a random variable in probability theory and statistics.\n",
    "\n",
    "# A PMF is used for discrete random variables, which can take on a finite or countably infinite number of values. The PMF of a random variable X is a function that maps each possible value x of X to the probability that X takes on the value x. In other words, the PMF gives the probability distribution of X in terms of a probability mass assigned to each possible outcome.\n",
    "\n",
    "# A PDF, on the other hand, is used for continuous random variables, which can take on an uncountably infinite number of values. The PDF of a random variable X is a function that describes the relative likelihood of X taking on different values within a range of values. The PDF is such that the integral of the PDF over any range of values gives the probability that X takes on a value within that range.\n",
    "\n",
    "# Here's an example: Suppose we have a fair six-sided die, and we roll it once. Let X be the number that comes up.\n",
    "\n",
    "# The PMF of X is given by:\n",
    "\n",
    "# P(X=1) = 1/6\n",
    "# P(X=2) = 1/6\n",
    "# P(X=3) = 1/6\n",
    "# P(X=4) = 1/6\n",
    "# P(X=5) = 1/6\n",
    "# P(X=6) = 1/6\n",
    "\n",
    "# In this case, the PMF assigns a probability mass of 1/6 to each possible outcome, since each outcome is equally likely.\n",
    "\n",
    "# Now suppose we have a random variable Y that represents the height of people in a population. Y is a continuous random variable since height can take on any value within a certain range. The PDF of Y might look something like a bell curve, with values close to the mean height being more likely and values far from the mean being less likely. The PDF of Y could be used to answer questions like \"What is the probability that a randomly selected person from the population has a height between 5'9'' and 6'1''?\" by integrating the PDF over the range of values in question.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: What is Cumulative Density Function(CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Cumulative Density Function(CDF) is a function that describes the probability that a random variable X is less than or equal to a certain value x. The CDF is defined for both discrete and continuous random variables and is used to describe the distribution of the random variable.\n",
    "\n",
    "# For a discrete random variable X, the CDF is defined as:\n",
    "\n",
    "# F(x) = P(X ≤ x) = ∑ P(X=i), for all i ≤ x\n",
    "\n",
    "# For a continuous random variable X, the CDF is defined as:\n",
    "\n",
    "# F(x) = P(X ≤ x) = ∫ f(u)du, from -∞ to x\n",
    "\n",
    "# where f(u) is the Probability Density Function of X.\n",
    "\n",
    "# The CDF gives the probability that X takes on a value less than or equal to x. It is a non-decreasing function, meaning that as x increases, the probability that X is less than or equal to x can only increase or stay the same. The CDF also ranges from 0 to 1, since the probability of X being less than or equal to negative infinity is 0, and the probability of X being less than or equal to infinity is 1.\n",
    "\n",
    "# Here's an example: Suppose we have a random variable X that represents the number of heads obtained when flipping a fair coin three times. The possible values of X are 0, 1, 2, and 3, with equal probabilities of 1/8 for each.\n",
    "\n",
    "# The CDF of X is:\n",
    "\n",
    "# F(0) = P(X ≤ 0) = 0\n",
    "# F(1) = P(X ≤ 1) = 1/8\n",
    "# F(2) = P(X ≤ 2) = 4/8 = 1/2\n",
    "# F(3) = P(X ≤ 3) = 8/8 = 1\n",
    "\n",
    "# The CDF tells us the probability that X is less than or equal to a certain value. For example, F(2) tells us the probability that we obtain two or fewer heads when flipping the coin three times, which is 1/2.\n",
    "\n",
    "# The CDF is useful because it allows us to answer questions about probabilities for a range of values of X. For example, we can use the CDF to answer questions like \"What is the probability that X is between 1 and 2?\" by subtracting the value of the CDF at 1 from the value of the CDF at 2, giving the probability that X is between 1 and 2.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The normal distribution, also known as the Gaussian distribution, is a continuous probability distribution that is widely used in statistics and probability theory. It is a bell-shaped curve that is symmetric around its mean, with most of the observations concentrated around the mean.\n",
    "\n",
    "# The normal distribution can be used as a model in a variety of situations, including:\n",
    "\n",
    "# 1. Height and weight of people in a population\n",
    "# 2. Test scores of a large group of students\n",
    "# 3. Errors in measurement or observation\n",
    "# 4. Natural phenomena such as rainfall or temperature\n",
    "# 5. Financial markets and economic variables like stock prices and GDP growth rates.\n",
    "\n",
    "# The parameters of the normal distribution are the mean (μ) and standard deviation (σ). The mean represents the central tendency of the distribution, while the standard deviation represents the spread of the distribution around the mean. The larger the standard deviation, the wider the bell-shaped curve of the distribution.\n",
    "\n",
    "# The shape of the normal distribution is determined by its mean and standard deviation. Specifically, the mean determines the location of the peak of the curve, while the standard deviation determines the width of the curve. \n",
    "\n",
    "# If the mean is increased, the entire curve shifts to the right, while decreasing the mean shifts the entire curve to the left. If the standard deviation is increased, the curve becomes wider and flatter, while decreasing the standard deviation makes the curve narrower and taller.\n",
    "\n",
    "# The normal distribution is often used in statistics because many real-world phenomena tend to follow a normal distribution. This is due to the central limit theorem, which states that the distribution of the sum (or average) of a large number of independent, identically distributed random variables tends towards a normal distribution. Therefore, the normal distribution can often be used to approximate the distribution of many different types of data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal distribution, also known as Gaussian distribution, is one of the most important probability distributions in statistics and probability theory. The importance of normal distribution is due to the following reasons:\n",
    "\n",
    "# 1. It is a widely used model for many natural and social phenomena that exhibit a bell-shaped distribution, where most of the observations fall near the mean, and the frequency of observations decreases as we move away from the mean in either direction.\n",
    "# 2. It provides a convenient way to estimate the probability of observing a value within a certain range or interval, which is useful in hypothesis testing, confidence interval estimation, and prediction.\n",
    "# 3. It is the foundation of many statistical methods, such as regression analysis, hypothesis testing, and analysis of variance(ANOVA).\n",
    "# 4. It is a critical assumption in many statistical models, such as linear regression, logistic regression, and time-series analysis.\n",
    "\n",
    "# Here are a few real-life examples of normal distribution:\n",
    "\n",
    "# 1. Heights of people: The distribution of heights in a population generally follows a normal distribution, with most people around the mean height and fewer people at the extremes of height.\n",
    "\n",
    "# 2. Test scores: The distribution of test scores in a large group of students is often close to a normal distribution, with most students scoring around the mean and fewer students scoring at the extremes.\n",
    "\n",
    "# 3. IQ scores: The distribution of IQ scores in a population is also approximately normal, with most people scoring around the mean IQ score of 100.\n",
    "\n",
    "# 4. Birth weights: The distribution of birth weights for newborns is often normally distributed, with most newborns weighing around the mean birth weight and fewer newborns at the extremes of weight.\n",
    "\n",
    "# 5. Measurement errors: The distribution of measurement errors in scientific experiments is often normal, with most errors around zero and fewer errors at the extremes.\n",
    "\n",
    "# 6. Financial returns: The daily returns of stocks, bonds, and other financial instruments often follow a normal distribution, with most days showing small gains or losses and fewer days showing large gains or losses.\n",
    "\n",
    "# In each of these examples, the normal distribution provides a useful and accurate model for the underlying data distribution, which allows statisticians and analysts to make inferences, draw conclusions, and make predictions based on the data.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli distribution is a discrete probability distribution that models a random experiment with only two possible outcomes, usually denoted by success(1) and failure(0). The distribution is named after Jacob Bernoulli, a Swiss mathematician who first studied it in the 17th century.\n",
    "\n",
    "# The probability mass function(PMF) of a Bernoulli distribution is given by:\n",
    "\n",
    "# P(X=1) = p\n",
    "# P(X=0) = 1 - p\n",
    "\n",
    "# where:\n",
    "# - X is the random variable that represents the outcome of the experiment\n",
    "# - p is the probability of success\n",
    "\n",
    "# An example of a Bernoulli distribution is a coin toss, where the two possible outcomes are heads(success) or tails(failure), and the probability of getting heads(p) is 0.5.\n",
    "\n",
    "# The difference between Bernoulli distribution and binomial distribution is that Bernoulli distribution models a single trial of an experiment with only two possible outcomes, while binomial distribution models the number of successes in a fixed number of independent and identical Bernoulli trials.\n",
    "\n",
    "# The probability mass function(PMF) of a binomial distribution is given by:\n",
    "\n",
    "# P(X=k) = (n choose k) * p ^ k * (1-p) ^ (n-k)\n",
    "\n",
    "# where:\n",
    "# - X is the random variable that represents the number of successes in n trials\n",
    "# - p is the probability of success in each trial\n",
    "# - k is the number of successes\n",
    "# - (n choose k) is the binomial coefficient, which represents the number of ways to choose k items from a set of n items.\n",
    "\n",
    "# An example of a binomial distribution is the number of heads in 10 coin tosses, where the probability of getting heads(p) is 0.5 in each toss. Here, n = 10 and k can take any value between 0 and 10.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the probability that a randomly selected observation will be greater than 60, we need to use the standard normal distribution formula:\n",
    "\n",
    "# z = (x - μ) / σ\n",
    "\n",
    "# where:\n",
    "# - x is the value we are interested in ( in this case, x = 60)\n",
    "# - μ is the mean of the distribution(μ=50)\n",
    "# - σ is the standard deviation of the distribution(σ=10)\n",
    "# - z is the standardized score\n",
    "\n",
    "# Substituting the values, we get:\n",
    "\n",
    "# z = (60 - 50) / 10 = 1\n",
    "\n",
    "# Now, we need to find the area under the standard normal distribution curve to the right of z = 1. We can use a standard normal distribution table or a calculator to find this area.\n",
    "\n",
    "# Using a calculator or statistical software, we can find that the area to the right of z = 1 is approximately 0.1587. Therefore, the probability that a randomly selected observation will be greater than 60 is 0.1587 or about 15.87 % .\n",
    "\n",
    "# Thus, the probability that a randomly selected observation will be greater than 60, assuming the dataset is normally distributed with a mean of 50 and a standard deviation of 10, is approximately 0.1587 or about 15.87 % .\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform distribution is a continuous probability distribution that models a random variable that can take on values uniformly over a specified interval. In other words, it is a distribution where all values in the interval have the same probability of being selected. The distribution is often used in situations where all outcomes are equally likely.\n",
    "\n",
    "# The probability density function (PDF) of a uniform distribution is given by:\n",
    "\n",
    "# f(x) = 1 / (b-a)   if a ≤ x ≤ b\n",
    "#       = 0          otherwise\n",
    "\n",
    "# where:\n",
    "# - x is the random variable that can take on values in the interval [a,b]\n",
    "# - a and b are the lower and upper bounds of the interval\n",
    "\n",
    "# An example of a uniform distribution is the random selection of a number between 1 and 6 (inclusive) using a fair six-sided die. In this case, each outcome (1, 2, 3, 4, 5, 6) is equally likely, and the probability of selecting any particular outcome is 1/6. The interval [1,6] represents the range of possible values of the random variable.\n",
    "\n",
    "# Another example of a uniform distribution is the arrival time of customers at a store during a specified time interval. If the store is open from 9:00 AM to 5:00 PM, and customers arrive randomly and uniformly over this interval, then the arrival time of any particular customer is equally likely to occur at any time between 9:00 AM and 5:00 PM. In this case, the interval [9:00 AM, 5:00 PM] represents the range of possible values of the random variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The z-score, also known as the standard score, is a statistical measure that indicates how many standard deviations a data point is from the mean of a distribution. The z-score is calculated by subtracting the mean from the data point and dividing the result by the standard deviation.\n",
    "\n",
    "# The formula for calculating the z-score is :\n",
    "\n",
    "# z = (x - μ) / σ\n",
    "\n",
    "# where:\n",
    "# - x is the data point\n",
    "# - μ is the mean of the distribution\n",
    "# - σ is the standard deviation of the distribution\n",
    "\n",
    "# The z-score tells us how far a data point is from the mean in terms of standard deviations. A positive z-score means the data point is above the mean, while a negative z-score means the data point is below the mean. A z-score of 0 means the data point is equal to the mean.\n",
    "\n",
    "# The importance of the z-score lies in its ability to standardize data from different distributions. By converting data to z-scores, we can compare data points from different distributions on the same scale, which makes it easier to compare and analyze data.\n",
    "\n",
    "# Z-scores are also important in hypothesis testing, as they are used to calculate the probability of observing a particular data point or a more extreme data point under the null hypothesis. The probability can be obtained from a standard normal distribution table or a calculator that calculates the area under the normal distribution curve.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Central Limit Theorem(CLT) is a fundamental concept in statistics that states that the sampling distribution of the sample mean of a large number of independent and identically distributed(IID) random variables will be approximately normally distributed, regardless of the underlying distribution of the population.\n",
    "\n",
    "# In other words, if we take multiple random samples of size n from any population with a finite mean and variance, the distribution of the sample means will tend to follow a normal distribution as the sample size increases, even if the population distribution is not normal. This holds true as long as the sample size is large enough(typically n ≥ 30), and the samples are independent and identically distributed.\n",
    "\n",
    "# The significance of the Central Limit Theorem is that it allows us to make statistical inferences about the population mean, even when we don't know the population distribution. This is because the normal distribution has well-understood properties, and we can use the properties of the normal distribution to calculate probabilities and construct confidence intervals for the population mean.\n",
    "\n",
    "# The CLT is also important in hypothesis testing because it provides a way to test hypotheses about the population mean using the sample mean. For example, we can use the sample mean and the standard error of the mean to calculate a test statistic, which can be compared to a standard normal distribution to determine the probability of observing the sample mean or a more extreme value under the null hypothesis.\n",
    "\n",
    "# Overall, the Central Limit Theorem is a critical concept in statistics that enables us to make inferences about population parameters using sample data, even when the population distribution is unknown or not normal.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Central Limit Theorem(CLT) makes several assumptions, which must be satisfied for it to hold true. These assumptions are:\n",
    "\n",
    "# 1. Random Sampling: The samples must be drawn randomly from the population.\n",
    "\n",
    "# 2. Independence: The samples must be independent of each other.\n",
    "\n",
    "# 3. Sample Size: The sample size should be sufficiently large. In general, a sample size of 30 or greater is considered large enough for the CLT to apply, but this may depend on the distribution of the population.\n",
    "\n",
    "# 4. Finite Population: The population from which the samples are drawn should have a finite mean and finite variance.\n",
    "\n",
    "# If these assumptions are met, the Central Limit Theorem can be used to approximate the sampling distribution of the sample mean, regardless of the underlying distribution of the population. However, if any of these assumptions are violated, the CLT may not hold true, and alternative methods may need to be used to make statistical inferences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
